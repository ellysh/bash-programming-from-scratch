## Операционные системы

### Предпосылки возникновения ОС

Большинство пользователей компьютера понимает, зачем нужна [**операционная система**](https://ru.wikipedia.org/wiki/Операционная_система#Функции) (ОС). Как правило, при покупке или загрузке из интернета какого-то приложения вы проверяете его системные требования. В них кроме требований к аппаратной части компьютера указана ОС, на которой приложение запускается. Получается, что ОС — это некоторая программная платформа, которая нужна для работы приложений. Но откуда взялось это требование? Почему нельзя просто купить компьютер и запустить на нём приложение вообще без ОС?

Эти вопросы кажутся бессмысленными только на первый взгляд. Подумайте сами: современные ОС универсальны и предлагают пользователю множество функций. Большинство из них каждому конкретному пользователю просто не нужно. Но эти функции зачастую невозможно отключить. Для их обслуживания ОС активно использует ресурсы компьютера. В результате для полезной нагрузки системы, то есть приложений с которыми работает пользователь, ресурсов остаётся намного меньше. Это приводит к медленной работе, зависаниям и даже перезагрузкам компьютера.

Обратимся к истории, чтобы выяснить причины возникновения ОС. На самом деле первая ОС [GM-NAA I/O](https://ru.wikipedia.org/wiki/GM-NAA_I/O) появилась только в 1956 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704). Все более ранние модели компьютеров обходились без ОС. Почему в них не возникало необходимости?

Основная причина заключается в быстродействии. Например, рассмотрим первый [**электромеханический компьютер**](http://chernykh.net/content/view/16/40/), сконструированный [Германом Холлеритом](https://ru.wikipedia.org/wiki/Холлерит,_Герман) в 1890 году. Этому компьютеру, получившему название табулятор, не требовалась ОС и [программы](https://ru.wikipedia.org/wiki/Компьютерная_программа) в современном смысле этого слова. Табулятор выполнял только ограниченный набор арифметических операций, который определялся его конструкцией. Данные для вычислений загружались с [**перфокарт**](https://ru.wikipedia.org/wiki/Перфокарта), которые представляли собой листки плотной бумаги с пробитыми отверстиями. Эти листки вручную подготавливались и укладывались в специальные приёмные устройства. Там они нанизывались на иглы и в местах отверстий происходило замыкание электрической цепи. Каждое замыкание приводило к увеличению механического счётчика, представлявшего собой вращающийся цилиндр. Результаты вычислений выводились на циферблаты, напоминавшие часы.

Иллюстрация 1-1 демонстрирует табулятор, построенный Германом Холлеритом.

{caption: "Иллюстрация 1-1. Табулятор Холлерита", height: "30%"}
![Табулятор Холлерита](images/GeneralInformation/tabulating-machine.jpg)

По современным меркам табулятор работал очень медленно. На это было несколько причин. Прежде всего данные для вычислений подготавливались вручную. Не было способа автоматически пробивать перфокарты. Далее загрузка перфокарт в компьютер также выполнялась вручную. Сам табулятор содержал большое количество механических частей: иглы для считывания данных, счётчики из вращающихся цилиндров, циферблаты для вывода результата. Вся эта механика работала медленно. На выполнение одной элементарной операции уходило время порядка одной секунды. Никакая автоматизация не могла бы ускорить эти процессы.

На смену табуляторам, работающим на вращающихся цилиндрах, пришли компьютеры, использующие [**реле**](https://ru.wikipedia.org/wiki/Реле). Реле — это механический элемент, который меняет своё состояние под воздействием электрического тока. Один из [первых релейных компьютеров](https://habr.com/ru/company/ua-hosting/blog/386247), называвшийся Z2, сконструировал немецкий инженер [Конрад Цузе](https://ru.wikipedia.org/wiki/Цузе,_Конрад) в 1939 году. Затем этот компьютер был усовершенствован в 1941 году и получил название Z3. Переход на реле позволил сократить время на выполнение каждой элементарной операции с секунды до миллисекунд.

Кроме возросшей скорости вычислений, компьютеры Цузе отличала ещё одна особенность. В них появилось понятие программы. Теперь с помощью перфокарт вводились не исходные данные задачи, а [**алгоритмы**](https://ru.wikipedia.org/wiki/Алгоритм) по которым она решалась. Для ввода данных использовалась клавиатура, отдалённо напоминающая печатную машинку. Такие компьютеры стали называться [**программируемыми**](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения) или универсальными.

I> Алгоритмом называется конечная последовательность инструкций для выполнения какого-либо вычисления или решения задачи.

Появление программируемых компьютеров стало важной вехой в развитии вычислительной техники. До этого момента машины выполняли только узкоспециализированные задачи. Это было слишком дорого и неэффективно. По этой причине многие инвесторы избегали вкладывать деньги в проекты по конструированию новых компьютеров. Эти проекты ограничивались только военными разработками в годы Второй мировой войны.

Следующим большим шагом стало создание компьютера [**ENIAC**](https://ru.wikipedia.org/wiki/ЭНИАК) (см. иллюстрацию 1-2) в 1946 году [Джоном Эккертом](https://ru.wikipedia.org/wiki/Эккерт,_Джон_Преспер) и [Джоном Мокли](https://ru.wikipedia.org/wiki/Мокли,_Джон). В качестве рабочих элементов в нём использовались не реле, а [**электровакуумные лампы**](https://ru.wikipedia.org/wiki/Электронная_лампа). Таким образом электромеханические компоненты с большим временем отклика были заменены на более быстрые электронные. Это позволило на порядок увеличить быстродействие компьютера и добиться выполнения одной элементарной операции за 200 микросекунд.

{caption: "Иллюстрация 1-2. ENIAC", height: "30%"}
![ENIAC](images/GeneralInformation/eniac.jpg)

В среде инженеров долго сохранялось скептическое отношение к электровакуумным лампам. Они были известны своей низкой надёжностью и высоким энергопотреблением. Никто не верил, что сконструированная на них машина вообще сможет работать. В ENIAC использовалось около 18 000 ламп. Они часто выходили из строя, но между их отказами компьютер успешно справлялся с вычислениями. ENIAC стал положительным примером использования ламп, который переубедил многих конструкторов.

ENIAC был программируемым компьютером. В нём алгоритм вычислений задавался с помощью комбинации переключателей и перемычек на коммутационных панелях. Такое программирование требовало значительного времени и одновременной работы нескольких человек. На иллюстрации 1-3 изображена одна из панелей для программирования ENIAC.

{caption: "Иллюстрация 1-3. Панель программирования ENIAC", height: "30%"}
![Панель программирования ENIAC](images/GeneralInformation/eniac-programming.jpg)

Для ввода исходных данных и вывода результатов использовались перфокарты, как и в предыдущих моделях компьютеров. Иногда перфокарты использовались для хранения промежуточных расчётов. Если исходная задача из-за своей сложности не могла быть решена сразу, она разбивалась на несколько подзадач. После выполнения каждой из них результаты выгружались на перфокартах, а компьютер перепрограммировался. Затем перфокарты загружались обратно в качестве входных данных.

Опыт эксплуатации ENIAC показал, что производительность компьютера ограничивают все механические операции: ручное перепрограммирование с помощью переключателей и перемычек, чтение и пробивание перфокарт. Несмотря на то, что сам компьютер обладал небывалой по тем временам производительность, для решения конкретной задачи на нём требовалось значительное время. Большую часть этого времени компьютер простаивал, ожидая программы или входных данных. Эти выводы послужили толчком для развития новых средств ввода данных и программ, а также вывода результатов вычислений.

Вычислительная мощность компьютеров увеличилась на порядок после перехода с электровакуумных ламп на [**транзисторы**](https://ru.wikipedia.org/wiki/Транзистор). Вместе с усовершенствованными средствами ввода-вывода это привело к более интенсивной эксплуатации компьютеров и их частому перепрограммированию. К этому времени вычислительные машины распространились за пределы военных проектов и стали использоваться крупными банками и корпорациями. В результате возрасло число и разнообразие запускаемых на них программ.

Часто программы исполнялись друг за другом без задержек, чтобы избежать простоя оборудования. Для автоматизации загрузки программ и вывода их результатов потребовались специальные решения. Именно для управления выполнением программ и была разработана первая ОС GM-NAA I/O.

Интенсивное использование компьютеров и разнообразие программ поставило не только задачу управления их исполнением. Дело в том, что функции компьютера определялись загружаемой в него программой. Например, если она включала в себя код для управления устройствами ввода-вывода, они были доступны. В противном случае эти устройства не работали. Для конкретной модели компьютера подключенное к нему оборудование менялось редко. Поэтому код для работы с ним копировался. Он кочевал из одной программы в другую, занимая лишнее место на устройствах хранения. Со временем этот код стали выносить в отдельную служебную программу, которая загружалась вместе с основной. Постепенно эти служебные программы вошли в состав первых ОС.

Вернёмся к нашему вопросу о необходимости операционных систем. Мы выяснили, что приложения могут работать и без них. Такие программы используются и сегодня. Например, это [**утилиты**](https://ru.wikipedia.org/wiki/Утилита) проверки памяти и разбивки диска, а также некоторые антивирусы. Однако, разработка таких программ требует больше времени и сил. В них приходится включать код для поддержки оборудования, который обычно предоставляется ОС. Чтобы уменьшить объём работы, а значит ускорить выпуск программы, разработчики активно используют возможности ОС.

### Возможности ОС

Почему мы начали изучение программирования с рассмотрения ОС? Иллюстрация 1-4 демонстрирует схему взаимодействия ОС с [**прикладными программами**](https://ru.wikipedia.org/wiki/Прикладное_программное_обеспечение) и [**аппаратным обеспечением**](https://ru.wikipedia.org/wiki/Аппаратное_обеспечение). Прикладные программы — это приложения, которые решают задачи пользователя (например, текстовый редактор, калькулятор, браузер). Под аппаратным обеспечением подразумеваются все электронные и механические компоненты компьютера (например, клавиатура, монитор, центральный процессор, видеокарта).

{caption: "Иллюстрация 1-4. Схема взаимодействия ОС с программами и аппаратным обеспечением", height: "50%"}
![Схема взаимодействия ОС](images/GeneralInformation/operating-system.png)

Согласно схеме, приложения получают доступ к аппаратным ресурсам не напрямую, а через [**системные библиотеки**](https://ru.wikipedia.org/wiki/Библиотека_(программирование)) ОС. Этот доступ предоставляется по определённым правилам. Программа работает только с теми возможностям устройств, которые поддерживаются ОС. Правила работы с устройствами определены в [**интерфейсе прикладного программирования**]((https://ru.wikipedia.org/wiki/API)), также известном как API (Application Programming Interface), который предоставляется системными библиотеками. Интерфейс — это набор соглашений о взаимодействии компонентов информационной системы. Как правило, интерфейсы описываются стандартами. Благодаря им, гарантируется совместимость компонентов системы.

API интерфейс описывает следующие аспекты взаимодействия программ и ОС:

1. Какая операция будет выполнена при вызове конкретной функции ОС?

2. Какие данные следует переданы ей на вход?

3. Какие данные функция вернёт в качестве результата?

Следование интерфейсу крайне важно как со стороны ОС, так и со стороны приложений. Это гарантирует их совместимость на уровне текущих версий и будущих модификаций. Без хорошо документированного, стандартизированного интерфейса такая совместимость была бы невозможна.

Мы уже выяснили, что приложения могут работать без ОС. Однако, она предлагает готовые решения для взаимодействия с аппаратными ресурсами компьютера, которые в противном случае пришлось бы решать разработчикам приложений. Это огромная работа. Тем более если учесть разнообразие комплектующих современных компьютеров. Все модели устройств (например, видеокарт) должны поддерживаться, иначе программа не сможет стабильно работать у всех пользователей.

Выясним, какие возможности предоставляет современная ОС через свой API интерфейс.

Все электронные и механические компоненты компьютера (аппаратное обеспечение), можно рассматривать как некоторые ресурсы, необходимые для вычислений. Именно с помощью этих компонентов выполняются программы пользователей.

Интерфейс отражает не только список возможностей оборудования, которыми может воспользоваться программа. Также он устанавливает порядок взаимодействия между несколькими программами и оборудованием. Рассмотрим пример.

Две программы не могут одновременно записывать данные на [жёсткий диск](https://ru.wikipedia.org/wiki/Жёсткий_диск#Технологии_записи_данных) в одну и ту же область. Во-первых, запись выполняется единственной магнитной головкой жёсткого диска. Во-вторых, данные, записанные первым приложением, будут затёрты данными второго. Поэтому одновременные запросы программ на запись должны блокироваться или помещаться в очередь и исполняться друг за другом. За эти механизмы отвечает ОС, а точнее её [**ядро**](https://ru.wikipedia.org/wiki/Ядро_операционной_системы) (см. иллюстрацию 1-4), в котором реализована [**файловая система**](https://ru.wikipedia.org/wiki/Файловая_система). Похожим образом ОС упорядочивает доступ ко всем [**периферийным**](https://ru.wikipedia.org/wiki/Периферийное_устройство) и внутренним устройствам компьютера. Этот доступ предоставляется через специальные программы, называемые [**драйверами устройств**](https://ru.wikipedia.org/wiki/Драйвер) (см. иллюстрацию 1-4).

Что такое периферийные устройства, и чем они отличаются от внутренних? К периферийным относятся все устройства, отвечающие за ввод и вывод информации, а также за её постоянное хранение. Например, клавиатура, мышь, микрофон, монитор, колонки, жёсткий диск. Внутренние устройства отвечают за обработку информации, то есть непосредственное исполнение программ. К ним относятся [**центральный процессор**](https://ru.wikipedia.org/wiki/Центральный_процессор) (central processing unit, CPU), [**оперативную память**](https://ru.wikipedia.org/wiki/Оперативная_память) (random-access memory, RAM), [**видеокарту**](https://ru.wikipedia.org/wiki/Видеокарта) (graphics processing unit, GPU).

Интерфейс доступа к аппаратным ресурсам — это не единственное, что предоставляет ОС. Кроме аппаратных есть ещё и программные ресурсы ОС. Это тот самый повторяющийся код, ставший со временем служебными программами и оформленный впоследствии в системные библиотеки (см. иллюстрацию 1-4). Некоторые из них обслуживают устройства, но некоторые выполняют полезные операции над входными данными. Например, компонент Windows под названием [**интерфейс графических устройств**](https://ru.wikipedia.org/wiki/GDI) даёт приложениям возможность манипулировать графическими объектами. С их помощью разработчики могут создавать пользовательский интерфейс для своих программ. К программным ресурсам относятся все компоненты ОС, установленные на компьютере. Кроме них ОС может также предоставлять доступ к алгоритмам сторонних приложений или библиотек.

ОС не только управляет ресурсами, но и организует работу запущенных приложений. Прежде всего код приложения надо загрузить с [**устройства хранения информации**](https://ru.wikipedia.org/wiki/Компьютерная_память) (будь то перфокарта или жёсткий диск) и поместить в оперативную память компьютера. Эта процедура нетривиальная, поскольку надо также загрузить код всех сторонних библиотек, которые используются приложением во время работы. Процесс запуска и исполнения программы мы рассмотрим подробнее в следующем разделе.

Если ОС многопользовательская, она контролирует доступ к данным. Таким образом каждый пользователь может работать только со своими собственными файлами и каталогами.

Подведём итог. ОС выполняет следующие функции:

1. Предоставляет и упорядочивает доступ к аппаратным ресурсам компьютера.

2. Предоставляет программные ресурсы в виде системных библиотек.

3. Запускает приложения, а также отвечает за ввод данных для них и вывод результата.

4. Организует взаимодействие приложений друг с другом.

5. Контролирует доступ пользователей к своим данным.

Изучив эти функции, внимательный читатель возможно догадался, что без ОС невозможно одновременное выполнение нескольких приложений. Ведь их разработчики не могут предусмотреть в каком сочетании программы будут выполняться. Только ОС имеет достаточно информации, чтобы эффективно распределить ресурсы компьютера в реальном времени.

### Современные ОС

Мы рассмотрели основные возможности ОС. Теперь с учётом наших новых знаний поговорим о современных ОС. Они отличаются друг от друга не столько предоставляемыми функциями, которые у них аналогичны, сколько способами их реализации. Эти особенности реализации и решения, которые к ним привели, называются [**архитектурой**](https://ru.wikipedia.org/wiki/Архитектура_программного_обеспечения).

У всех современных ОС есть две важные особенности, которые во многом определяют их поведение и способ взаимодействия с пользователем. Речь идёт о многозадачности и графическом интерфейсе. Рассмотрим их подробнее.

#### Многозадачность

Подавляющее большинство современных ОС [**многозадачны**](https://ru.wikipedia.org/wiki/Многозадачность). Это означает, что они поддерживают одновременное исполнение нескольких программ. Почему это свойство оказалось важным? Ведь системы, обладающие этим свойством, вытеснили те, у которых его не было.

Задача увеличения эффективности использования компьютеров стояла особенно остро в 1960-е годы. Тогда компьютеры стоили дорого и, следовательно, дорога была каждая минута их работы. Крупные компании и университеты, которые могли позволить себе купить мейнфрейм, считали неприемлемым любой его простой.

Ранние операционные системы позволяли последовательно исполнять программы друг за другом без задержек. Это экономило время, необходимое на переключение компьютера с одной задачи на другую. В таких системах несколько программ и входные данные для них подготавливались заранее и записывались на устройство хранения (например, магнитную ленту). Эта лента подавалась на устройство чтения компьютера. Он последовательно исполнял программы и выводил их результаты на устройство вывода (например, принтер). Такой режим работы получил название [**пакетная обработка**](https://ru.wikipedia.org/wiki/Пакетное_задание) ([batch processing](https://en.wikipedia.org/wiki/Batch_processing)).

Пакетная обработка увеличила эфективность использования времени мейнфреймов. Она автоматизировала загрузку программ и частично исключила из этого процесса человека-оператора. Однако, у системы оставалось ещё одно [**узкое место**](https://ru.wikipedia.org/wiki/Узкое_место). Дело в том, что вычислительная мощность процессоров стала значительно превосходить скорость работы периферийных устройств. Это привело к простоям CPU.

I> Узкое место (bottleneck) — компонент или ресурс информационной системы, который ограничивает её общую производительность или пропускную способность.

Рассмотрим пример. Представьте, что мейнфрейм последовательно выполняет вычислительные программы. Данные для них считываются с магнитной ленты, а результаты печатаются на принтере. ОС загружает каждую программу и исполняет её инструкции, затем загружает следующую и так далее. Проблемы возникают на этапах чтения данных и печати результата. Время доступа к данным на магнитной ленте огромно в масштабах центрального процессора. Между двумя последовательными операциями чтения, он мог бы выполнить значительный объём вычислений. Но он этого не делает, поскольку все ресурсы компьютера используются только текущей программой, которая в данный момент загружается в память. То же самое происходит с выводом результатов расчётов на печать. Принтер, как чисто механическое устройство, работает очень медленно. Эта проблема простоя оборудования и привела к идее [**мультипрограммирования**](https://ru.wikipedia.org/wiki/Мультипрограммирование).

Мультипрограммирование подразумевает одновременную загрузку сразу нескольких программ в память компьютера. Первая из них начинает выполняться до тех пор, пока доступны все необходимые ей ресурсы. Как только один из ресурсов оказывается занят, её выполнение останавливается. Например, программе нужны данные, хранящиеся на жёстком диске. Пока контроллер читает первую их часть, он занят и не может обработать запрос на чтение следующей части. В этом случае ОС прекращает выполнение первой программы и переключается на вторую. Она в свою очередь исполняется до конца или до того момента, когда нужный ей ресурс окажется занят. После этого опять происходит переключение.

Мультипрограммирование стало ранним прототипом многозадачности, которая реализована во всех современных ОС. Мультипрограммирование хорошо справляется с режимом пакетной обработки. Однако, этот подход распределения нагрузки совершенно не подходит для систем, предусматривающих [**интерактивное взаимодействие**](https://ru.wikipedia.org/wiki/Интерактивность). В них каждое действие пользователя (например, нажатие клавиши) является событием, которое требует какой-то реакции со стороны системы (например, добавление нового символа в текстовый документ). Обработка событий должна происходить с минимальными задержками, иначе пользователь заметит зависания работающей программы. Проблема мультипрограммирования в том, что очередная задача выполняется непредсказуемо долго. До тех пор пока текущая программа не выполнена до конца или ей не был запрошен занятый ресурс, переключения задачи не произойдёт и никакие действия пользователя не могут быть обработаны.

Многозадачность решает проблему быстрого отклика при интерактивной работе с компьютером. Способ её реализации постепенно развивался и усложнялся. В современных ОС применяется [**вытесняющая многозадачность**](https://ru.wikipedia.org/wiki/Вытесняющая_многозадачность) с псевдопараллельной обработкой задач. Это означает, что ОС самостоятельно принимает решение о том, какая программа будет выполняться в данный момент времени. При этом выборе учитываются приоритеты работающих приложений. То есть более приоритетные будут получать аппаратные ресурсы чаще, чем низкоприоритетные. Механизм переключения задач реализован в ядре ОС и называется [**планировщиком задач**](https://ru.wikipedia.org/wiki/Диспетчер_операционной_системы).

Псевдопараллельность обработки означает, что в каждый момент времени выполняется только одна задача. При этом переключение между задачами происходит настолько быстро, что пользователь этого не замечает. Ему кажется, что компьютер сразу реагирует на любое его действие. Однако на самом деле, каждая программа и компонент ОС получают аппаратные ресурсы в строго определённые моменты времени.

В случае компьютеров с несколькими процессорами или [многоядерными](https://ru.wikipedia.org/wiki/Ядро_микропроцессора) процессорами одновременно исполняются несколько программ. Грубо говоря, число одновременно выполняемых задач равно числу ядер всех процессоров компьютера. При этом принцип вытесняющей многозадачности с постоянным переключением задач сохраняется. Он универсален и хорошо справляется с балансировкой нагрузки многопроцессорных и многоядерных систем. Это позволяет выдерживать приемлемое время отклика на действия пользователя.

#### Интерфейс пользователя

Ещё одна общая черта современных ОС для [**персональных компьютеров**](https://ru.wikipedia.org/wiki/Персональный_компьютер) (ПК) и ноутбуков — это наличие [**графического интерфейса пользователя**](https://ru.wikipedia.org/wiki/Графический_интерфейс_пользователя) (graphical user interface или GUI). С его помощью пользователь может запускать приложения, а также конфигурировать аппаратное обеспечение и компоненты ОС. Рассмотрим подробнее историю его возникновения.

Интерактивный способ работы с компьютером стал известен широкому кругу пользователей только в 1960 году после анонса [мини-компьютера](https://en.wikipedia.org/wiki/Minicomputer) [PDP-1](https://ru.wikipedia.org/wiki/PDP-1) фирмой [Digital Equipment Corporation](https://ru.wikipedia.org/wiki/Digital_Equipment_Corporation). Может быть не совсем понятна причина, по которой конструкторы и пользователи компьютеров вообще заинтересовались интерактивностью. В 1950-е годы на рынке мейнфреймов доминировали компьютеры IBM. Они работали в режиме пакетной обработки и успешно справлялись с вычислительными задачами того времени. Их операционные системы с поддержкой мультипрограммирования автоматизировали загрузку программ и обеспечивали хорошую производительность.

Идея интерактивной работы с компьютером возникла в рамках военного проекта SAGE, выполнявшегося по заказу ВВС США. Проект заключался в разработке автоматизированной системы ПВО для обнаружения советских бомбардировщиков. Проблема, которую решали конструкторы, заключалась в обработке данных с радаров. Эти данные выводились человеку-оператору, который в режиме реального времени отдавал команды системе ПВО. Для решения этой задачи требовались новые методы работы с компьютером. Существовавшие в то время подходы (наподобие пакетной обработки) не удовлетворяли требованиям проекта, поскольку система ПВО должна реагировать максимально быстро на обнаруженную угрозу. В ходе проекта SAGE был сконструирован первый интерактивный компьютер [AN/FSQ-7](https://en.wikipedia.org/wiki/AN/FSQ-7_Combat_Direction_Central) (см иллюстрацию 1-5). В нём данные о воздушных угрозах выводились на [**электронно-лучевой монитор**](https://ru.wikipedia.org/wiki/Кинескоп), а для ввода команд использовалось [**световое перо**](https://ru.wikipedia.org/wiki/Световое_перо).

{caption: "Иллюстрация 1-5. Компьютер AN/FSQ-7"}
![Компьютер AN/FSQ-7](images/GeneralInformation/AN-FSQ-7.jpg)

Метод интерактивной работы с компьютером стал известен в научных кругах и быстро набрал популярность. Главная проблема пакетной обработки связана с растянутой по времени разработкой и отладкой программ. После подготовки алгоритма и записи его на устройство хранения, программисту приходилось часами ждать результатов его выполнения на мейнфрейме. Компьютеры в то время были очень загружены работой и все поступающие программы обрабатывались в порядке очереди. Если в программе обнаруживалась ошибка, её алгоритм исправлялся, записывался на устройство хранения и снова попадал в очередь на исполнение. Таким образом до момента исправления всех ошибок и получения нужного результата проходили дни.

Интерактивный режим позволял программисту запускать программу и сразу по её завершению выводить на экран результат. Благодаря этому, продуктивность работы с компьютером значительно возрастала. Можно было за несколько часов добиться результатов, на которые раньше требовались дни.

Появление интерактивного режима привело к новым задачам. Прежде всего понадобился новый способ балансирования нагрузки, который бы позволил добиться приемлемого времени отклика системы на действия пользователя. Как мы уже знаем, многозадачность новых ОС решила эту проблему.

На самом деле интерактивный режим возможен и на однозадачных ОС (например, [MS-DOS](https://ru.wikipedia.org/wiki/DOS)). Однако, совмещение интерактивности и однозадачности стало целесообразно только с появлением относительно дешёвых персональных компьютеров. Во времена дорогих мейнфреймов, ресурсы одного компьютера одновременно предоставлялись нескольким пользователям. Каждый из них запускал свои программы, которые выполнялись параллельно. Такой режим работы получил название [**разделение времени**](https://ru.wikipedia.org/wiki/Разделение_времени) (time-sharing). Без многозадачности обеспечить интерактивную работу нескольких пользователей было невозможно.

Другая задача, поставленная интерактивным режимом, связана со способом взаимодействия пользователя и компьютера. Как именно должны выглядеть и работать устройства ввода и вывода информации, чтобы ими было удобно пользоваться? Однозначных ответов на эти вопросы в 1960-х годах ещё не было.

Прототипом первого пользовательского интерфейса для компьютера стало устройство под названием [**телетайп**](https://ru.wikipedia.org/wiki/Телетайп) (teletype) (см. иллюстрацию 1-6). Он представляет собой электромеханическую печатную машинку, подключённую с помощью проводов к другому такому же устройству. Ранние версии телетайпа использовались для передачи текстовых сообщений между двумя абонентами. Отправитель набирал текст на своём устройстве. Каждое нажатие клавиши передавалось на устройство получателя и распечатывалось в виде буквы на бумаге.

{caption: "Иллюстрация 1-6. Телетайп Model 33", height: "50%"}
![Телетайп Model 33](images/GeneralInformation/teletype.jpg)

Телетайпы стали применять для удалённого доступа к мейнфреймам. Такое устройство получило название [**терминал**](https://ru.wikipedia.org/wiki/Компьютерный_терминал). Пользователи набирали на клавиатуре команды, которые затем отправлялись на компьютер. Он их выполнял и отправлял результат обратно на терминал, который распечатывал полученные данные на бумаге. Позднее устройство печати заменили на монитор. В результате получился [**интерфейс командной строки**](https://ru.wikipedia.org/wiki/Интерфейс_командной_строки) (command-line interface или CLI). Принцип его работы напоминает классический телетайп — пользователь вводит команды одну за другой. Компьютер их последовательно исполняет и выводит на экран результат.

Пример современного интерфейса командной строки приведён на иллюстрации 1-7. Это окно [**эмулятора терминала**](https://ru.wikipedia.org/wiki/Эмулятор_терминала) [Terminator](https://en.wikipedia.org/wiki/Terminator_(terminal_emulator)), в котором запущен интерпретатор командной строки Bash. В окне выведены результаты работы программ ping и ls.

{caption: "Иллюстрация 1-7. Интерфейс командной строки", height: "50%"}
![Интерфейс командной строки](images/GeneralInformation/cli.png)

Интерфейс командной строки активно применяется и сегодня. У него есть ряд преимуществ перед более привычным для пользователей графическим интерфейсом. Главное преимущество CLI в том, что он не требователен к вычислительным ресурсам. Он работает одинаково стабильно и без задержек как на низкопроизводительных встраиваемых компьютерах, так и на мощных серверах. Если применять CLI для удалённого доступа к компьютеру, он не требователен к качеству канала связи и его пропускной способности. Даже с медленным соединением команды будут переданы на сервер без искажений и исполнены.

Главная проблема интерфейса командной строки заключается в сложности его освоения. Пользователю доступны сотни команд с различными входными параметрами, которые определяют их режим работы. Чтобы запомнить хотя бы часто используемые команды, требуется немало времени.

Попытки решить проблему с наглядным представлением доступных команд и результатов их работы, привели к созданию [**текстового интерфейса пользователя**](https://ru.wikipedia.org/wiki/Текстовый_интерфейс_пользователя) (textual user interface или TUI). В нём наряду с буквенными и цифровыми символами используется [**псевдографика**](https://ru.wikipedia.org/wiki/Псевдографика). Псевдографикой называются специальные символы, с помощью которых на экране отображаются графические примитивы (например, линии, прямоугольники, треугольники и т.д.). Иллюстрация 1-8 демонстрирует типичный текстовый интерфейс. Это вывод статистики использования системных ресурсов программой htop.

{caption: "Иллюстрация 1-8. Текстовый интерфейс пользователя", height: "50%"}
![Текстовый интерфейс пользователя](images/GeneralInformation/tui.png)

Дальнейший рост производительности компьютеров позволил заменить псевдографику на реальные графические элементы такие как окна, иконки, кнопки и т.д. В результате возник полноценный графический интерфейс, который применяется в современных ОС.

Графический интерфейс ОС Windows приведён на иллюстрации 1-9. Это скриншот рабочего стола с развёрнутыми окнами трёх одновременно работающих приложений: Проводника, Блокнота и Калькулятора.

{caption: "Иллюстрация 1-9. Графический интерфейс пользователя"}
![Графический интерфейс пользователя](images/GeneralInformation/gui.png)

Первый графический интерфейс был разработан для мини-компьютера [Xerox Alto](https://ru.wikipedia.org/wiki/Xerox_Alto) (см. иллюстрацию 1-10) в 1973 году в исследовательском центре [Xerox PARC](https://ru.wikipedia.org/wiki/Xerox_PARC). Однако, интерфейс не получил широкого распространения вплоть до 1980-х годов из-за его высоких требований к памяти и производительности компьютеров. Первый ПК Lisa с графическим интерфейсом был выпущен на рынок компанией Apple только в 1983 году.

{caption: "Иллюстрация 1-10. Мини-компьютер Xerox Alto", height: "50%"}
![Мини-компьютер Xerox Alto](images/GeneralInformation/xerox-alto.jpg)

#### Семейства ОС

Сегодня на рынке персональных компьютеров доминируют три семейства ОС:

* [Windows](https://ru.wikipedia.org/wiki/Windows)
* [Linux](https://ru.wikipedia.org/wiki/Linux)
* [macOS](https://ru.wikipedia.org/wiki/MacOS)

Что именно подразумевается, когда говорят о семействе ОС? Этот термин означает ряд версий ОС, которые следуют одним и тем же архитектурным решениям, а также сохраняют некоторые особенности реализации тех или иных функций.

Почему разработчики каждой ОС предпочитают придерживаться одной и той же архитектуры, а не предлагают что-то принципиально новое в следующих версиях? На самом деле изменения в современных ОС происходят, но постепенно и медленно. Причина этого в [**обратной совместимости**](https://ru.wikipedia.org/wiki/Обратная_совместимость). Эта совместимость предполагает наличие некоторых старых функций в новой версии ОС. Они нужны для корректной работы написанных ранее программ. На первый взгляд это требование может показаться необязательным. Но на самом деле это серьёзное ограничение для разработки программного обеспечения. Давайте разберёмся, почему это так.

Представьте, что вы разработали программу для ОС Windows и продаёте её. Иногда пользователи обнаруживают в ней ошибки, которые вы успешно исправляете. Время от времени вы добавляете в неё новые функции. Теперь представьте, что выходит новая версия Windows, на которой ваша программа перестаёт работать. У пользователей есть два решения: ждать от вас новой версии программы, в которой проблема решена, или отказаться от обновления Windows. Теперь предположим, что новая версия ОС принципиально отличается от предыдущей. Это значит, что вашу программу придётся переписать буквально с нуля. Посчитайте всё время, которое вы уже потратили на исправление ошибок и добавление новых функций. Эту работу в полном объёме придётся повторить. Скорее всего вы откажетесь от этой идеи и предложите пользователям оставаться на старой версии Windows. Теперь представьте, что таких программ как ваша много. Их разработчики придут к тому же решению, что и вы. В результате новая версия Windows окажется никому не нужна. В этом и заключается проблема обратной совместимости. Именно поэтому и существуют семейства ОС.

Влияние приложений, доступных под конкретную ОС, сложно переоценить. Например, ОС Windows и персональные компьютеры от IBM обязаны своим успехом табличному процессору [Lotus 1-2-3](https://ru.wikipedia.org/wiki/Lotus_1-2-3). Он запускался только на ПК от IBM, работающих под управлением Windows. Ради Lotus 1-2-3 пользователи покупали и первое и второе. Такие популярные приложения, выводящие какую-то платформу на широкий рынок, получили название [**killer application**](https://ru.wikipedia.org/wiki/Killer_application) (букв. убойное приложение). Похожая ситуация сложилась с табличным процессором [VisiCalc](https://ru.wikipedia.org/wiki/VisiCalc), который способствовал распространению компьютеров [Apple II](https://ru.wikipedia.org/wiki/Apple_II). Точно так же бесплатные компиляторы языков C, Fortran и Pascal подогрели интерес к Unix в университетских кругах. За каждой из трёх доминирующих сегодня ОС стоит какое-то killer application. Далее распространению этих ОС способствовал [сетевой эффект](https://ru.wikipedia.org/wiki/Сетевой_эффект), когда разработчики приложений выбирали в качестве целевой программной платформы именно ту, которая уже была установлена на компьютеры большинства пользователей.

Вернёмся к нашему списку семейств ОС. Windows и Linux примечательны тем, что не привязаны к конкретной аппаратной платформе. Это значит, что купив любой персональный компьютер или ноутбук, вы без особых трудностей сможете установить на него эти ОС. macOS в отличие от них рассчитана на запуск только на устройствах Apple. Чтобы установить macOS на другую аппаратную платформу, вам понадобится её неофициальная [модифицированная версия](https://ru.wikipedia.org/wiki/OSx86). Совместимость с аппаратной платформой — это хороший пример архитектурного решения. Но таких решений много, и все вместе они формируют особенности каждого семейства.

ОС во многом определяет инфраструктуру, доступную программисту. Она диктует не только инструменты разработки, такие как IDE, компилятор, система сборки, но и некоторые архитектурные решения самих запускаемых на ней приложений. Можно говорить о некоторой сложившейся культуре написания программ под конкретную ОС. Это очень важный момент, который следует всегда учитывать: под разные ОС программы принято разрабатывать по-разному.

Рассмотрим различие культур разработки программ подробнее на примере Windows и Linux.

#### Windows

Windows — это [проприетарная](https://ru.wikipedia.org/wiki/Проприетарное_программное_обеспечение) ОС. Исходные коды проприетарного программного обеспечения закрыты для постороннего изучения и модификации. Вы не сможете законным способом узнать о нём больше, чем разработчики посчитают нужным вам сообщить. Чтобы установить Windows на свой компьютер, вам надо купить её у компании Microsoft. Однако, часто эта ОС уже предустановлена на новые компьютеры и ноутбуки, а её цена включена в конечную стоимость устройства.

Обратите внимание, что целевой платформой Windows были и остаются относительно дешёвые персональные компьютеры. Многие могут позволить себе купить такое устройство. Следовательно, рынок потенциальных пользователей огромен. Microsoft стремится всеми силами сохранить конкурентное преимущество на этом рынке. Компания опасается появления аналогов своей ОС с такими же возможностями. Именно поэтому Microsoft заботится о защите своей интеллектуальной собственности не только техническими, но и юридическими путями. Строго говоря, пользовательское соглашение запрещает вам исследовать внутреннее устройство ОС.

За всё время существования семейства ОС Windows под него было написано много прикладных программ. Первые из них (например, пакет офисных приложений [Microsoft Office](https://ru.wikipedia.org/wiki/Microsoft_Office) или [стандартные приложения Windows](https://ru.wikipedia.org/wiki/Категория:Стандартные_приложения_Windows)) создавались самой компанией Microsoft. Для сторонних разработчиков они послужили в некотором роде образцом для подражания. Microsoft при разработке своих приложений придерживалась того же принципа закрытости, что и при разработке ОС: исходные коды недоступны конечным пользователям, форматы данных недокументированны, сторонние утилиты не могут получить доступа к возможностям приложений. Опять же все эти решения были продиктованы заботой о защите интеллектуальной собственности компании от конкурентов.

Сторонние разработчики программ последовали примеру Microsoft и зачастую стали придерживаться той же философии закрытости. Большинство получившихся приложений самодостаточны и независимы друг от друга. Форматы их данных, как правило, закодированы и недокументированны.

Если вы опытный пользователь компьютера, то сразу узнаете типичное Windows приложение. Это окно с такими [элементами интерфейса](https://ru.wikipedia.org/wiki/Элемент_интерфейса), как кнопки, поля ввода, вкладки и т.д. Через это окно пользователь манипулирует каким-то данными (например, текстом, изображением или звуковой записью). Результат работы сохраняется на жёсткий диск компьютера и может быть повторно загружен в том же самом приложении. Очень велика вероятность, что если вы напишете собственную Windows-программу, она будет выглядеть и работать похожим образом. Именно такая преемственность решений и имеется ввиду, когда мы говорим о сложившейся культуре разработки под конкретную ОС.

#### Linux

Linux является идейным наследником ОС [Unix](https://ru.wikipedia.org/wiki/Unix) и следует её [**спецификациям**](https://ru.wikipedia.org/wiki/Спецификация). Спецификация — это документ с требованиями к системе, который также определяет её поведение и внутреннее устройство. Получается, что Linux заимствовал многие идеи и решения Unix, что в результате привело к похожему поведению.

Сама Unix возникла в конце 1960-х годов. Она создавалась как хобби-проект двумя инженерами компании Bell Labs: [Кеном Томпсоном](https://ru.wikipedia.org/wiki/Томпсон,_Кен) и [Деннисом Ритчи](https://ru.wikipedia.org/wiki/Ритчи,_Деннис). Они участвовали в крупном проекте компании по разработке ОС [**Multics**](https://ru.wikipedia.org/wiki/Multics) для нового мейнфрейма GE-645 (см. иллюстрацию 1-11) от компании General Electric. Кроме Bell Labs и General Electric над проектом также работал Массачусетский Технологический Институт (MIT).

{caption: "Иллюстрация 1-11. Мэйнфрейм модели GE-645", height: "30%"}
![Мэйнфрейм модели GE-645](images/GeneralInformation/ge-645.jpg)

В ОС Multics планировалось реализовать много инновационных для того времени идей. Одной из них было разделение времени. Как вы помните, это означает, что с одним мейнфреймом одновременно может работать несколько пользователей. При этом вычислительные ресурсы компьютера разделяются между ними с помощью многозадачности.

Разработка Multics затягивалась и Bell Labs решила выйти из проекта. Однако многие инженеры компании хотели продолжать работу над ним. На этой волне Кен Томпсон решил создать собственную ОС для компьютера GE-645. Для этого он начал писать ядро и продублировал некоторые механизмы Multics. Однако, General Electric потребовала вернуть свой дорогой мейнфрйем, переданный Bell Labs во временное пользование. В результате Кен Томпсон остался без аппаратной платформы для разработки.

Параллельно с работой над аналогом Multics Кен писал компьютерную игру [Space Travel](https://ru.wikipedia.org/wiki/Space_Travel). Она запускалась на мейнфрейме General Electric прошлого поколения GE-635, который работал под управлением ОС [GECOS](https://ru.wikipedia.org/wiki/GCOS). Этот компьютер представлял собой шкафы с электроникой и стоил порядка 7 500 000$. Его вычислительные ресурсы активно использовались для нужд компании и были постоянно заняты. Поэтому Кен решил портировать свою игру на относительно недорогой и реже используемый коллегами мини-компьютер [PDP-7](https://ru.wikipedia.org/wiki/PDP-7) (см. иллюстрацию 1-12) стоимостью порядка 72 000$. Проблема заключалась в том, что игра использовала возможности ОС GECOS, которые были недоступны на PDP-7. Поэтому Кену и присоединившемуся к нему Деннису пришлось реализовать эти возможности в виде набора библиотек и систем, которые впоследствии развились в самостоятельную ОС Unix.

{caption: "Иллюстрация 1-12. Мини-компьютер PDP-7", height: "30%"}
![Мини-компьютер PDP-7](images/GeneralInformation/pdp-7.jpg)

Очевидно, в своём проекте разработчики Unix не заботились о защите интеллектуальной собственности, поскольку не собирались её продавать. ОС разрабатывалась для собственных нужд и распространялась с открытым исходным кодом, доступным для изучения и модификации любым желающим. Изначально круг пользователей ограничивался сотрудниками компании Bell Labs. Позднее AT&T, которой принадлежала Bell Labs, предоставила исходный код Unix высшим учебным заведениям США. Таким образом развитие ОС продолжилось уже в университетских кругах.

ОС Linux была создана в 1991 году [Линусом Торвальдсом](https://ru.wikipedia.org/wiki/Торвальдс,_Линус) во время его обучения в Хельсинкском университете. Линус решал чисто практическую проблему: в то время персональные компьютеры не имели полноценной Unix-совместимой ОС. В университете студенты выполняли учебные задания на мини-компьютере MicroVAX под управлением Unix, но дома у них не было оборудования, подходящего для её запуска. Единственной альтернативой Unix была ОС [Minix](https://ru.wikipedia.org/wiki/Minix), разработанная Эндрю Таненбаумом в 1987 году для персональных компьютеров IBM с процессорами Intel 80268. Но эта ОС создавалась для учебных целей, и поэтому Эндрю отказывался вносить в неё изменения для поддержки более современных компьютеров. Эти изменения неизбежно привели бы к усложнению системы и сделали бы её непригодной для обучения студентов.

Линус задался целью написать Unix-совместимую ОС для своего нового компьютера IBM с процессором Intel 80386. Её прототипом стала учебная ОС Minix. Как и у создателей Unix, у него не было коммерческих интересов, связанных с продажей результата своего труда. Он разрабатывал систему для собственных нужд. Поэтому его ОС стала бесплатной и свободно распространялась с исходным кодом через интернет.

На самом деле Linux — это не более чем ядро ОС, предоставляющее функции для работы с памятью, файловой системой, периферийными устройствами, а также управлением процессорным временем. Большинство функций системы доступны через свободные [пользовательские компоненты GNU](https://ru.wikipedia.org/wiki/Проект_GNU), которые Линус включил в [дистрибутив](https://ru.wikipedia.org/wiki/Дистрибутив_Linux) своей ОС.

Изначально у Linux, как у и Unix, не было графической подсистемы. Все приложения пользователь запускал из командной строки. Только некоторые сложные приложения имели текстовый интерфейс. Со временем в Linux появилась оконная система [X Window System](https://ru.wikipedia.org/wiki/X_Window_System), а вместе с ней и приложения с графическим интерфейсом, более привычные пользователям Windows.

Условия в которых возникла и развивалась ОС Unix (а позднее и Linux), во многом определили культуру написания приложений. В этой культуре предпочтение отдаётся узкоспециализированным утилитам командной строки, которые выполняют только одну конкретную задачу, но делают это максимально эффективно. Эти утилиты выводят свои результаты в открытом формате данных (как правило [текстовом](https://ru.wikipedia.org/wiki/Текстовые_данные)), а их исходный код всегда доступен для изучения и модификации.

Культура разработки приложений в Linux значительно отличается от стандартов, принятых в Windows. В Windows каждое приложение монолитно и самостоятельно выполняет все свои задачи. Оно не полагается на сторонние утилиты, которые могут оказаться платными или недоступными для пользователя по какой-то причине. Разработчик должен рассчитывать только на себя. Он не в праве требовать от пользователя купить что-то дополнительное для работы своего приложения. В Linux же подавляющее большинство утилит бесплатны, взаимозаменяемы и легко доступны через интернет. Поэтому вполне естественно, что какое-то приложение потребует загрузить и установить недостающие ему системные компоненты или другое приложение.

Даже монолитные графические приложения в Linux обычно предоставляют дополнительный интерфейс командной строки. Таким образом они органично вписываются в экосистему и легко интегрируются с другими утилитами и приложениями.

Когда сложный вычислительный процесс строится на сочетании нескольких узкоспециализированных приложений, возникает задача составления алгоритма их совместной работы. Именно для этой задачи была создана [командная оболочка](https://ru.wikipedia.org/wiki/Командная_оболочка_Unix) [Bourne shell](https://ru.wikipedia.org/wiki/Bourne_shell) и её потомок [Bash](https://ru.wikipedia.org/wiki/Bash). В этой книге мы будем работать только с Bash, который полностью вытеснил Bourne shell на современных Linux-системах.

Стоит признать, что нельзя отдать однозначное предпочтение культуре Linux перед Windows. Их сравнение давно служит поводом для бесконечных споров. Каждая из культур имеет свои достоинства и недостатки. Например, широко распространённые в Windows монолитные приложения лучше справляются с задачами, требующими интенсивных расчётов. При комбинации узкоспециализированных Linux-утилит в этом случае возникают накладные расходы, связанные с их запуском и передачей данных между ними. В результате задача выполняется дольше.

Сегодня можно наблюдать синтез культур Windows и Linux. Всё больше коммерческих приложений портируются на Linux: браузеры, инструменты для разработки программ, игры, мессенджеры и т.д. При этом их разработчики часто не готовы вносить изменения, продиктованные Linux-культурой. Такие изменения требуют времени и сил. Кроме того они усложняют сопровождение продукта. Вместо одного приложения получается несколько: под каждую платформу разная версия. Намного проще портировать приложение в том же виде, в каком оно разрабатывалось под Windows. В результате под Linux всё чаще встречаются приложения выполненные в типичном Windows-стиле. О плюсах и минусах этого процесса можно спорить. Но одно очевидно: чем больше приложений запускается на ОС, тем популярнее она становится благодаря сетевому эффекту.

I> Подробнее о культуре разработки в Unix и Linux вы можете узнать из книги [Эрика Реймонда "Искусство программирования в Unix"](https://ru.wikipedia.org/wiki/Философия_Unix#Реймонд:_Искусство_программирования_в_Unix).
